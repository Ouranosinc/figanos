{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Miscellaneous\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "\n",
    "# setup notebook\n",
    "%config InlineBackend.print_figure_kwargs = {'bbox_inches':'tight'}\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import xclim as xc\n",
    "import xsdba\n",
    "\n",
    "import figanos.matplotlib as fg\n",
    "\n",
    "\n",
    "fg.utils.set_mpl_style(\"ouranos\")\n",
    "\n",
    "# load dataset\n",
    "url = \"https://pavics.ouranos.ca//twitcher/ows/proxy/thredds/dodsC/birdhouse/disk2/cccs_portal/indices/Final/BCCAQv2_CMIP6/tx_max/YS/ssp585/ensemble_percentiles/tx_max_ann_BCCAQ2v2+ANUSPLIN300_historical+ssp585_1950-2100_30ymean_percentiles.nc\"\n",
    "opened = xr.open_dataset(url, decode_timedelta=False, engine=\"netcdf4\")\n",
    "ds_time = opened.isel(lon=500, lat=250)[[\"tx_max_p50\", \"tx_max_p10\", \"tx_max_p90\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Climate Stripes\n",
    "\n",
    "Climate stripe diagrams are a way to present the relative change of climate variables or indicators over time, in a simple and aesthetically-pleasing manner. Figanos creates such plots through the stripes function.\n",
    "\n",
    "While the vast majority of these diagrams will show the yearly change of a variable relative to a reference point, `stripes()` will adjust the size of the stripes to fill the figure to accommodate datasets with time intervals greater than a year.\n",
    "\n",
    "The function accepts DataArrays, one-variable Datasets, and a dictionary containing scenarios (DataArrays or Datasets) to be stacked. The plot will be divided in as many sub-axes as there are entries in the dictionary. Normally, these scenarios would contain identical data up to a certain year, where the scenarios diverge; the `divide` argument should be used to create an axis separation at this point of divergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two datasets of mean annual temperature relative to the 1981-2010 period\n",
    "url1 = \"https://pavics.ouranos.ca/twitcher/ows/proxy/thredds/dodsC/birdhouse/ouranos/portraits-clim-1.3/MPI-ESM-LR_rcp85_tx_mean_annual.nc\"\n",
    "rcp85 = xr.open_dataset(url1, decode_timedelta=False, engine=\"netcdf4\")\n",
    "rcp85 = rcp85.sel(lon=-73, lat=46, method=\"nearest\")\n",
    "rcp85_deltas = rcp85 - rcp85.sel(time=slice(\"1981\", \"2010\")).mean(dim=\"time\")\n",
    "rcp85_deltas.tx_mean_annual.attrs[\"long_name\"] = \"Mean annual daily max temp relative to 1981-2010\"\n",
    "rcp85_deltas.tx_mean_annual.attrs[\"units\"] = \"K\"\n",
    "\n",
    "url2 = \"https://pavics.ouranos.ca/twitcher/ows/proxy/thredds/dodsC/birdhouse/ouranos/portraits-clim-1.3/MPI-ESM-LR_rcp45_tx_mean_annual.nc\"\n",
    "rcp45 = xr.open_dataset(url2, decode_timedelta=False, engine=\"netcdf4\")\n",
    "rcp45 = rcp45.sel(lon=-73, lat=46, method=\"nearest\")\n",
    "rcp45_deltas = rcp45 - rcp45.sel(time=slice(\"1981\", \"2010\")).mean(dim=\"time\")\n",
    "rcp45_deltas.tx_mean_annual.attrs[\"long_name\"] = \"Annual mean of daily max temp relative to 1981-2010\"\n",
    "rcp45_deltas.tx_mean_annual.attrs[\"units\"] = \"K\"\n",
    "\n",
    "# Plot\n",
    "fg.stripes({\"rcp45\": rcp45_deltas, \"rcp85\": rcp85_deltas}, divide=2006)\n",
    "\n",
    "# plt.savefig(\"images/stripes.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "Like most of the other functions, `stripes()` will attempt to find a colormap that is appropriate for the data variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a similar dataset with precipitation data\n",
    "url3 = (\n",
    "    \"https://pavics.ouranos.ca/twitcher/ows/proxy/thredds/dodsC/birdhouse/ouranos/portraits-clim-1.3/MPI-ESM-LR_rcp85_precip_accumulation_annual.nc\"\n",
    ")\n",
    "prec = xr.open_dataset(url3, decode_timedelta=False, engine=\"netcdf4\")\n",
    "prec = prec.sel(lon=-73, lat=46, method=\"nearest\")\n",
    "prec_deltas = prec - prec.sel(time=slice(\"1981\", \"2010\")).mean(dim=\"time\")\n",
    "prec_deltas.precip_accumulation_annual.attrs[\"long_name\"] = \"Total annual precipitation change relative to 1981-2010\"\n",
    "prec_deltas.precip_accumulation_annual.attrs[\"units\"] = \"mm\"\n",
    "\n",
    "ax = fg.stripes(prec_deltas)\n",
    "ax.set_title(\"Precipitation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Violin Plots\n",
    "\n",
    "Violin plots are a practical tool for visualizing the statistical distribution of data in an ensemble, combining a box plot with a kernel density plot. The violin function wraps Seaborn's [violinplot](https://seaborn.pydata.org/generated/seaborn.violinplot.html#seaborn.violinplot) function to directly accept xarray objects, and incorporates other figanos features. The `data` argument can be a DataArray (one \"violin\"), a Dataset (as many \"violins\" as there are variables in the Dataset), or a dictionary of either types. In the case of a dictionary, its keys will become the \"violin\" labels.\n",
    "\n",
    "As with other functions, when `use_attrs` is passed and `data` is a dictionary, attributes from the first dictionary entry will be put on the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fg.violin(ds_time, use_attrs={\"title\": \"description\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "# plt.savefig(\"images/violin.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "The optional `color` argument combines the Seaborn function's `color` and `palette` arguments. A single color or a list of colors can be passed. Integers can be passed instead of strings to refer to colors of the currently used stylesheet. If the list of colors is shorter than the number of variables on the plot, the colors are repeated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = {\n",
    "    \"p10\": ds_time.tx_max_p10,\n",
    "    \"p50\": ds_time.tx_max_p50,\n",
    "    \"p90\": ds_time.tx_max_p90,\n",
    "}\n",
    "\n",
    "ax = fg.violin(my_data, plot_kw={\"orient\": \"h\"}, color=[3, \"purple\", \"#78bf84\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Heatmaps\n",
    "\n",
    "Similarly to violin plots, the heatmap function wraps Seaborn's [heatmap](https://seaborn.pydata.org/generated/seaborn.heatmap.html) function to directly accept xarray objects, and incorporates other figanos features. The `data` argument can be a DataArray, a Dataset, or a dictionary of either types and of `length=1`. There is no real benefit to using a dictionary, but it is accepted in order to be coherent with other functions in the package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a diagnostics Dataset from scratch\n",
    "improvement = np.random.rand(7, 7)\n",
    "diagnostics = xr.DataArray(\n",
    "    data=improvement,\n",
    "    coords=dict(\n",
    "        realization=[\n",
    "            \"model1\",\n",
    "            \"model2\",\n",
    "            \"model3\",\n",
    "            \"model4\",\n",
    "            \"model5\",\n",
    "            \"model6\",\n",
    "            \"model7\",\n",
    "        ],\n",
    "        properties=[\n",
    "            \"aca_pr\",\n",
    "            \"aca_tasmax\",\n",
    "            \"aca_tasmin\",\n",
    "            \"corr_tasmax_pr\",\n",
    "            \"corr_tasmax_tasmin\",\n",
    "            \"mean_tasmax\",\n",
    "            \"mean_pr\",\n",
    "        ],\n",
    "    ),\n",
    ")\n",
    "\n",
    "diagnostics.attrs[\"long_name\"] = \"% of improved grid cells\"\n",
    "\n",
    "# Plot a heatmap\n",
    "fg.heatmap(\n",
    "    diagnostics,\n",
    "    divergent=0.5,\n",
    "    plot_kw={\"vmin\": 0, \"linecolor\": \"w\", \"linewidth\": 1.5},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "In order to produce reliable results, the xarray object passed to `heatmap()` has to have only two dimensions. Under the hood, the function converts the DataArray containing the data to a pandas DataFrame before plotting it. Using `transpose=True` swaps the `x` and `y` axes.\n",
    "\n",
    "The colorbar kwargs are accessible through the nesting of `cbar_kws` in `plot_kw`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = fg.heatmap(\n",
    "    diagnostics,\n",
    "    transpose=True,\n",
    "    cmap=\"bwr_r\",\n",
    "    divergent=0.5,\n",
    "    plot_kw={\n",
    "        \"cbar_kws\": {\"label\": \"Proportion of cells improved\"},\n",
    "        \"annot\": True,\n",
    "    },\n",
    ")\n",
    "\n",
    "# Remove the grid labels\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_ylabel(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "# plt.savefig(\"images/heatmap.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Triangle Heatmaps\n",
    "\n",
    "The `triheatmap` function is based on the matplotlib function [tripcolor](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.tripcolor.html). It can create a heatmap with 2 or 4 triangles in each square of the heatmap.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a fake data\n",
    "da = xr.DataArray(\n",
    "    data=np.random.rand(2, 3, 4),\n",
    "    coords=dict(\n",
    "        realization=[\"A\", \"B\"],\n",
    "        method=[\"a\", \"b\", \"c\"],\n",
    "        experiment=[\"ssp126\", \"ssp245\", \"ssp370\", \"ssp585\"],\n",
    "    ),\n",
    ")\n",
    "da.name = \"pr\"  # to guess the cmap\n",
    "# will be automatically detected for the cbar label\n",
    "da.attrs[\"long_name\"] = \"precipitation\"\n",
    "da.attrs[\"units\"] = \"mm\"\n",
    "\n",
    "# Plot a heatmap\n",
    "fg.triheatmap(\n",
    "    da,\n",
    "    z=\"experiment\",  # which dimension should be represented by triangles\n",
    "    divergent=True,  # for the cmap\n",
    "    cbar=\"unique\",  # only show one cbar\n",
    "    plot_kw={\n",
    "        \"vmin\": -1,\n",
    "        \"vmax\": 1,\n",
    "    },  # we are only showing the 1st cbar, so make sure the cbar of each triangle is the same\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "# plt.savefig(\"images/triangle1.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a fake data\n",
    "da = xr.DataArray(\n",
    "    data=np.random.rand(4, 3, 2),\n",
    "    coords=dict(\n",
    "        realization=[\"A\", \"B\", \"C\", \"D\"],\n",
    "        method=[\"a\", \"b\", \"c\"],\n",
    "        season=[\"DJF\", \"JJA\"],\n",
    "    ),\n",
    ")\n",
    "da.attrs[\"description\"] = \"La plus belle saison de ma vie\"\n",
    "\n",
    "# Plot a heatmap\n",
    "fg.triheatmap(\n",
    "    da,\n",
    "    z=\"season\",\n",
    "    cbar=\"each\",  # show a cbar per triangle\n",
    "    use_attrs={\"title\": \"description\"},\n",
    "    cbar_kw=[\n",
    "        {\"label\": \"winter\"},\n",
    "        {\"label\": \"summer\"},\n",
    "    ],  # Use a list to change the cbar associated with each triangle type (upper or lower)\n",
    "    plot_kw=[{\"cmap\": \"winter\"}, {\"cmap\": \"summer\"}],\n",
    ")  # Use a list to change each triangle type (upper or lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "# plt.savefig(\"images/triangle2.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## Taylor Diagrams\n",
    "\n",
    "Taylor diagrams are a useful way to compare simulation datasets to a reference dataset. They allow for graphical representation of the standard deviation of both the simulation and reference datasets, the correlation between both, and the root mean squared error (a function of the two previous statistical properties).\n",
    "\n",
    "The `taylordiagram()` function creates each point on the Taylor diagram from an object created using `xsdba.measures.taylordiagram`, as illustrated below.\n",
    "\n",
    "### Important Notes\n",
    "* The structure of the matplotlib axes being different from the other figanos functions, this function does not have an `ax` argument, and creates its own figure.\n",
    "* To change the axis labels, use the `std_label` and `corr_label` arguments, rather than the `ax.set_xlabel()` method.\n",
    "* Dataset with negative correlations with the reference dataset will not be plotted.\n",
    "* To modify the appearance of the reference point (on the `x`-axis), use the keyword 'reference' in `plot_kw`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "da_ref = ds_time[\"tx_max_p50\"]\n",
    "\n",
    "# Toy data with same mean as `da_ref` & modify deviations with trigonometric functions\n",
    "homogenous_ref_mean = xr.full_like(da_ref, da_ref.mean(dim=\"time\"))\n",
    "simd = {}\n",
    "for i, f_trig in enumerate([np.cos, lambda x: np.cos(x) ** 2, np.tan]):\n",
    "    da = homogenous_ref_mean + f_trig(da_ref.values)\n",
    "    da.attrs[\"units\"] = da_ref.attrs[\"units\"]\n",
    "    simd[f\"model{i}\"] = xsdba.measures.taylordiagram(sim=da, ref=da_ref)\n",
    "\n",
    "fg.taylordiagram(\n",
    "    simd,\n",
    "    std_range=(0, 1.3),\n",
    "    contours=5,\n",
    "    contours_kw={\"colors\": \"green\"},\n",
    "    plot_kw={\"reference\": {\"marker\": \"*\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.savefig(\"images/taylor.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "### Normalized Taylor Diagram\n",
    "\n",
    "If we normalize the standard deviation of our measures, many Taylor diagrams with difference references can be combined in a single plot. In the following example, we have datasets with two variables (`tasmax, pr`) and three location coordinates. For each location (3) and variable (2), a `taylordiagram` measure is computed. Each set of correlation and standard deviation is then plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pooch  # FIXME: remove downloader when xclim fixes the issue with nimbus\n",
    "from xclim.testing.utils import nimbus\n",
    "\n",
    "from figanos import __version__ as __figanos_version__\n",
    "\n",
    "\n",
    "downloader = pooch.HTTPDownloader(headers={\"User-Agent\": f\"figanos {__figanos_version__}\"})\n",
    "n = nimbus()\n",
    "\n",
    "ref = n.fetch(\"sdba/ahccd_1950-2013.nc\", downloader=downloader)\n",
    "ds_ref = xr.open_dataset(ref)\n",
    "sim = n.fetch(\"sdba/nrcan_1950-2013.nc\", downloader=downloader)\n",
    "ds_sim = xr.open_dataset(sim)\n",
    "\n",
    "for v in ds_ref.data_vars:\n",
    "    ds_sim[v] = xc.core.units.convert_units_to(ds_sim[v], ds_ref[v], context=\"hydro\")\n",
    "\n",
    "# Here, we have three locations, two variables. We stack variables to convert from\n",
    "# a Dataset to a DataArray.\n",
    "da_ref = xsdba.stack_variables(ds_ref)\n",
    "da_sim = xsdba.stack_variables(ds_sim)\n",
    "\n",
    "# Each location/variable will have its own set of taylor parameters\n",
    "out = xsdba.measures.taylordiagram(ref=da_ref, sim=da_sim, dim=\"time\")\n",
    "\n",
    "# If we normalize the taylor diagrams, they can be compared on the same plot\n",
    "out[{\"taylor_param\": [0, 1]}] = out[{\"taylor_param\": [0, 1]}] / out[{\"taylor_param\": 0}]\n",
    "\n",
    "# in xclim >= 0.50.0 : Normalization can be done when computing taylordiagram measure\n",
    "# out = sdba.measures.taylordiagram(ref=da_ref, sim=da_sim, dim=\"time\", normalize=True)\n",
    "\n",
    "# The `markers_key` and `colors_key` are used to separate between two different features.\n",
    "# Here, the type of marker is used to distinguish between locations, and the color\n",
    "# distinguishes between variables. If those parameters are not specified, then each\n",
    "# pair (location, multivar)  has simply its own color.\n",
    "fg.taylordiagram(out, markers_key=\"location\", colors_key=\"multivar\", ref_std_line=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "## Partition Plots\n",
    "\n",
    "Partition plots show the fraction of uncertainty associated with different components.\n",
    "Xclim has a few different [partition functions](https://xclim.readthedocs.io/en/stable/api.html#uncertainty-partitioning).\n",
    "\n",
    "This tutorial is a reproduction of [xclim's documentation](https://xclim.readthedocs.io/en/stable/notebooks/partitioning.html).\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Note that you could also use the [xscen library](https://xscen.readthedocs.io/en/latest/index.html) to build and ensemble from a catalog with `xscen.ensembles.build_partition_data`.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch data\n",
    "import pandas as pd\n",
    "import xclim.ensembles\n",
    "\n",
    "\n",
    "# The directory in the Atlas repo where the data is stored\n",
    "# host = \"https://github.com/IPCC-WG1/Atlas/raw/main/datasets-aggregated-regionally/data/CMIP6/CMIP6_tas_land/\"\n",
    "host = \"https://raw.githubusercontent.com/IPCC-WG1/Atlas/main/datasets-aggregated-regionally/data/CMIP6/CMIP6_tas_land/\"\n",
    "\n",
    "# The file pattern, e.g. CMIP6_ACCESS-CM2_ssp245_r1i1p1f1.csv\n",
    "pat = \"CMIP6_{model}_{scenario}_{member}.csv\"\n",
    "\n",
    "# Here we'll download data only for a very small demo sample of models and scenarios.\n",
    "\n",
    "# Download data for a few models and scenarios.\n",
    "models = [\"ACCESS-CM2\", \"CMCC-CM2-SR5\", \"CanESM5\"]\n",
    "members = [\"r1i1p1f1\", \"r1i1p1f1\", \"r1i1p1f1\"]\n",
    "scenarios = [\"ssp245\", \"ssp370\", \"ssp585\"]\n",
    "\n",
    "# Create the input ensemble.\n",
    "data = []\n",
    "for model, member in zip(models, members, strict=False):\n",
    "    for scenario in scenarios:\n",
    "        url = host + pat.format(model=model, scenario=scenario, member=member)\n",
    "\n",
    "        # Fetch data using pandas\n",
    "        df = pd.read_csv(url, index_col=0, comment=\"#\", parse_dates=True)[\"world\"]\n",
    "        # Convert to a DataArray, complete with coordinates.\n",
    "        da = xr.DataArray(df).expand_dims(model=[model], scenario=[scenario]).rename(date=\"time\")\n",
    "        data.append(da)\n",
    "\n",
    "# Combine DataArrays from the different models and scenarios into one.\n",
    "ens_mon = xr.combine_by_coords(data)[\"world\"]\n",
    "\n",
    "# Then resample the monthly time series at the annual frequency\n",
    "ens = ens_mon.resample(time=\"YS\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "Compute uncertainties with xclim and use `fractional_uncertainty` to have the right format to plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute uncertainty\n",
    "mean, uncertainties = xclim.ensembles.hawkins_sutton(ens, baseline=(\"2016\", \"2030\"))\n",
    "\n",
    "\n",
    "# frac= xc.ensembles.fractional_uncertainty(uncertainties)\n",
    "\n",
    "\n",
    "# FIXME: xc.ensembles.fractional_uncertainty has not been released yet. Until until it is released, here it is.\n",
    "def fractional_uncertainty(u: xr.DataArray):\n",
    "    \"\"\"\n",
    "    Return the fractional uncertainty.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    u : xr.DataArray\n",
    "        Array with uncertainty components along the `uncertainty` dimension.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    xr.DataArray\n",
    "        Fractional, or relative uncertainty with respect to the total uncertainty.\n",
    "    \"\"\"\n",
    "    uncertainty = u / u.sel(uncertainty=\"total\") * 100\n",
    "    uncertainty.attrs.update(u.attrs)\n",
    "    uncertainty.attrs[\"long_name\"] = \"Fraction of total variance\"\n",
    "    uncertainty.attrs[\"units\"] = \"%\"\n",
    "    return uncertainty\n",
    "\n",
    "\n",
    "frac = fractional_uncertainty(uncertainties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "fg.partition(\n",
    "    frac,\n",
    "    start_year=\"2016\",  # change the x-axis\n",
    "    show_num=True,  # put the number of element of each uncertainty source in the legend FIXME: will only appear after xclim releases 0.48\n",
    "    fill_kw={\n",
    "        \"variability\": {\"color\": \"#DC551A\"},\n",
    "        \"model\": {\"color\": \"#2B2B8B\"},\n",
    "        \"scenario\": {\"color\": \"#275620\"},\n",
    "    },\n",
    "    line_kw={\"lw\": 2},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "# plt.savefig(\"images/partition.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "## Logos\n",
    "\n",
    "Logos can also be added to plots if desired using the `figanos.utils.plot_logo()` function. This function requires that logos are passed as `pathlib.Path()` objects or installed and called by their name (as `str`).\n",
    "\n",
    "Figanos offers the `Logos()` convenience class for setup and management of logos so that they can be reused as needed. Logos can be used to set default logos as well as install custom logos, if desired. Logo files are saved to the user's config folder so that they can be reused.\n",
    "\n",
    "By default, the `figanos_logo.png` is installed on initialization, while the Ouranos set of logos can be installed if desired.\n",
    "\n",
    "For more information on logos, see the Logos documentation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from figanos import Logos\n",
    "\n",
    "\n",
    "# Installing the default logos\n",
    "logos = Logos()\n",
    "print(f\"Default logo is found at: {logos.default}.\")\n",
    "\n",
    "# Installing the Ouranos logos\n",
    "logos.install_ouranos_logos(permitted=True)\n",
    "\n",
    "# Show all installed logos\n",
    "logos.installed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To set a new default logo we can simply use an existing entry\n",
    "logos.set_logo(logos.logo_ouranos_horizontal_couleur, \"default\")\n",
    "print(f\"Default logo is found at: {logos.default}\")\n",
    "logos.set_logo(logos.logo_ouranos_vertical_couleur, \"my_custom_logo\")\n",
    "print(f\"my_custom_logo installed at: {logos.my_custom_logo}.\")\n",
    "\n",
    "# Show all installed logos\n",
    "logos.installed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = fg.timeseries(my_data, show_lat_lon=\"upper left\", legend=\"edge\")\n",
    "\n",
    "# Plotting with the default logo\n",
    "# fg.utils.plot_logo(ax, loc='lower right', alpha=0.8, width=120)\n",
    "\n",
    "# Plotting with a custom logo, resized with pixels\n",
    "fg.utils.plot_logo(\n",
    "    ax,\n",
    "    logo=\"my_custom_logo\",\n",
    "    loc=\"lower right\",\n",
    "    width=100,\n",
    "    alpha=0.8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {
    "nbsphinx": "hidden",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plt.savefig(\"images/logo.png\", bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "figanos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
